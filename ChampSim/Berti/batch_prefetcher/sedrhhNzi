#include "vbertimix_small.h"
#include "bingo_frame.h"
#define LANZAR_INT 8
#define PAGE_MASK 0xFFF


// Last edit: 27 - Sept - 2021 12:10

// FIFO queue
//#define SIZE_RR 16
//uint64_t RR[NUM_CPUS][SIZE_RR] = {0};
//uint64_t RR_cycle[NUM_CPUS][SIZE_RR] = {0};
//uint64_t RR_dx[NUM_CPUS] = {0};
bool spec_intructions_complete;

const double L1_THRESHOLD=0.80;
const double L2_THRESHOLD=0.20;
const double LLC_THRESHOLD=1.0;
struct PAGE_SETTING{
    const uint64_t REGION_SIZE = 32 * 1024;

    const int GHB_SIZE = 256; //6*max(pc_page)
    const int PC_INDEX_SIZE = 8; // 16 32 64 128 256
    const int PAGE_INDEX_SIZE = 32; // 16 32 64 128 256
    const int MAX_HIS_LEN = 8;
    //索引表的way数是固定的16


    const uint64_t PAGE_STRIDE_TABLE_SIZE = 64;// follow with page or page*2
    const uint64_t PC_STRIDE_TABLE_SIZE = 16;// follow with pc or pc*2
    const uint64_t DELTA_NUM = 8;



    const int ALL_MAX_PF = 12;
    const uint64_t PAGE_CONFIDENCE_MAX = 16;
    const uint64_t PAGE_LANZAR_INT = 8;




};


uint8_t warmup_flag_l1 = 0;


uint64_t hash_index(uint64_t key, uint64_t page_size, uint64_t pc_size,  bool is_pc){ 
    
    // uint64_t index = key % this->num_sets;
    // uint64_t tag = key / this->num_sets;  
    // cout << "key: " << key ;
    if(is_pc){
        int pc_set_num = pc_size / 16;
        int all_set_num = (pc_size + page_size)/ 16;
        // cout << " tag " << ((key / pc_set_num)*all_set_num) + (key % pc_set_num)<< endl ;
        return ((key / pc_set_num)*all_set_num) + (key % pc_set_num);
    }
    else{
        int pc_set_num = pc_size / 16;
        int page_set_num = page_size / 16;
        int all_set_num = (pc_size + page_size)/ 16;
        // cout << " tag " << (((key/page_set_num)*all_set_num) + (key % page_set_num) + pc_set_num) << endl ;
        return ((key/page_set_num)*all_set_num) + (key % page_set_num) + pc_set_num;
    }

}

void notify_prefetch(uint64_t addr, uint64_t tag, uint32_t cpu, uint64_t cycle)
{
    //这个是预取时，进入到缺失状态寄存器的时间
    latency_table_add(addr, tag, cpu, 0, cycle & TIME_MASK);
}

bool compare_greater_stride_t(stride_t a, stride_t b)
{
    if (a.rpl == L1 && b.rpl != L1) return 1;
    else if (a.rpl != L1 && b.rpl == L1) return 0;
    else
    {
        if (a.rpl == L2 && b.rpl != L2) return 1;
        else if (a.rpl != L2 && b.rpl == L2) return 0;
        else
        {
            if (a.rpl == L2R && b.rpl != L2R) return 1;
            if (a.rpl != L2R && b.rpl == L2R) return 0;
            else
            {
                if (std::abs(a.stride) < std::abs(b.stride)) return 1;
                return 0;
            }
        }
    }
}

bool compare_greater_stride_t_per(stride_t a, stride_t b)
{
    if (a.per > b.per) return 1;
    else
    {
        if (std::abs(a.stride) < std::abs(b.stride)) return 1;
        return 0;
    }
}

/******************************************************************************/
/*                      Latency table functions                               */
/******************************************************************************/
void latency_table_init(uint32_t cpu)
{
    /*
     * Init pqmshr (latency) table
     *
     * Parameters:
     *      - cpu: cpu
     */
    for (uint32_t i = 0; i < LATENCY_TABLE_SIZE; i++)
    {
        latencyt[cpu][i].tag  = 0;
        latencyt[cpu][i].addr = 0;
        latencyt[cpu][i].time = 0;
        latencyt[cpu][i].pf   = 0;
    }
}

uint64_t latency_table_get_ip(uint64_t line_addr, uint32_t cpu)
{
    /*
     * Return 1 or 0 if the addr is or is not in the pqmshr (latency) table
     *
     * Parameters:
     *  - line_addr: address without cache offset
     *  - cpu: actual cpu
     *
     * Return: 1 if the line is in the latency table, otherwise 0
     */

    for (uint32_t i = 0; i < LATENCY_TABLE_SIZE; i++)
    {
        // Search if the line_addr already exists
        if (latencyt[cpu][i].addr == line_addr && latencyt[cpu][i].tag) 
            return latencyt[cpu][i].tag;
    }

    return 0;
}

uint8_t latency_table_add(uint64_t line_addr, uint64_t tag, uint32_t cpu, 
        uint8_t pf)
{
    /*
     * Save if possible the new miss into the pqmshr (latency) table
     *
     * Parameters:
     *  - line_addr: address without cache offset
     *  - cpu: actual cpu
     *  - access: is the entry accessed by a demand request
     */
    return latency_table_add(line_addr, tag, cpu, pf, current_core_cycle[cpu] & TIME_MASK);
}

uint8_t latency_table_add(uint64_t line_addr, uint64_t tag, uint32_t cpu, 
        uint8_t pf, uint64_t cycle)
{
    /*
     * Save if possible the new miss into the pqmshr (latency) table
     *
     * Parameters:
     *  - line_addr: address without cache offset
     *  - cpu: actual cpu
     *  - access: is theh entry accessed by a demand request
     *  - cycle: time to use in the latency table
     *
     * Return: 1 if the addr already exist, otherwise 0.
     */

    latency_table_t *free;
    free = nullptr;

    for (uint32_t i = 0; i < LATENCY_TABLE_SIZE; i++)
    {
        // Search if the line_addr already exists. If it exist we does not have
        // to do nothing more
        if (latencyt[cpu][i].addr == line_addr) 
        {
            latencyt[cpu][i].time = cycle;
            latencyt[cpu][i].tag  = tag;
            latencyt[cpu][i].pf   = pf;
            return latencyt[cpu][i].pf;
        }

        // We discover a free space into the latency table, save it for later
        //if (latencyt[cpu][i].addr == 0) free = &latencyt[cpu][i];
        if (latencyt[cpu][i].tag == 0) free = &latencyt[cpu][i];
    }

    // No free space!! This cannot be truth
    if (free == nullptr) return 0;

    // We save the new entry into the latency table
    free->addr = line_addr;
    free->time = cycle;
    free->tag  = tag;
    free->pf   = pf;

    return free->pf;
}

uint64_t latency_table_del(uint64_t line_addr, uint32_t cpu)
{
    /*
     * Remove the address from the latency table
     *
     * Parameters:
     *  - line_addr: address without cache offset
     *  - cpu: actual cpu
     *
     *  Return: the latency of the address
     */
    for (uint32_t i = 0; i < LATENCY_TABLE_SIZE; i++)
    {
        // Line already in the table
        if (latencyt[cpu][i].addr == line_addr)
        {
            uint64_t latency = (current_core_cycle[cpu] & TIME_MASK)
                - latencyt[cpu][i].time; // Calculate latency

            //latencyt[cpu][i].addr = 0; // Free the entry
            latencyt[cpu][i].tag  = 0; // Free the entry
            latencyt[cpu][i].time = 0; // Free the entry
            latencyt[cpu][i].pf   = 0; // Free the entry

            // Return the latency
            return latency;
        }
    }

    // We should always track the misses
    //assert(0);
    return 0;
}

uint64_t latency_table_get(uint64_t line_addr, uint32_t cpu)
{
    /*
     * Return 1 or 0 if the addr is or is not in the pqmshr (latency) table
     *
     * Parameters:
     *  - line_addr: address without cache offset
     *  - cpu: actual cpu
     *
     * Return: 1 if the line is in the latency table, otherwise 0
     */

    for (uint32_t i = 0; i < LATENCY_TABLE_SIZE; i++)
    {
        // Search if the line_addr already exists
        if (latencyt[cpu][i].addr == line_addr) return latencyt[cpu][i].time;
    }

    return 0;
}

/******************************************************************************/
/*                       Shadow Cache functions                               */
/******************************************************************************/
void shadow_cache_init(uint32_t cpu)
{
    /*
     * Init shadow cache
     *
     * Parameters:
     *      - cpu: cpu
     */
    for (uint8_t i = 0; i < L1D_SET; i++)
    {
        for (uint8_t ii = 0; ii < L1D_WAY; ii++)
        {
            scache[cpu][i][ii].addr = 0;
            scache[cpu][i][ii].lat  = 0;
            scache[cpu][i][ii].pf   = 0;
        }
    }
}

uint8_t shadow_cache_add(uint32_t cpu, uint32_t set, uint32_t way, 
        uint64_t line_addr, uint8_t pf, uint64_t latency)
{
    /*
     * Add block to shadow cache
     *
     * Parameters:
     *      - cpu: cpu
     *      - set: cache set
     *      - way: cache way
     *      - addr: cache block v_addr
     *      - access: the cache is access by a demand
     */
    scache[cpu][set][way].addr = line_addr;
    scache[cpu][set][way].pf   = pf;
    scache[cpu][set][way].lat  = latency;
    return scache[cpu][set][way].pf;
}

uint8_t shadow_cache_get(uint32_t cpu, uint64_t line_addr)
{
    /*
     * Init shadow cache
     *
     * Parameters:
     *      - cpu: cpu
     *      - addr: cache block v_addr
     *
     * Return: 1 if the addr is in the l1d cache, 0 otherwise
     */

    for (uint32_t i = 0; i < L1D_SET; i++)
    {
        for (uint32_t ii = 0; ii < L1D_WAY; ii++)
        {
            if (scache[cpu][i][ii].addr == line_addr) return 1;
        }
    }

    return 0;
}

uint8_t shadow_cache_pf(uint32_t cpu, uint64_t line_addr)
{
    /*
     * Init shadow cache
     *
     * Parameters:
     *      - cpu: cpu
     *      - addr: cache block v_addr
     *
     * Return: 1 if the addr is in the l1d cache, 0 otherwise
     */

    for (uint32_t i = 0; i < L1D_SET; i++)
    {
        for (uint32_t ii = 0; ii < L1D_WAY; ii++)
        {
            if (scache[cpu][i][ii].addr == line_addr) 
            {
                scache[cpu][i][ii].pf = 0;
                return 1;
            }
        }
    }

    return 0;
}

uint8_t shadow_cache_is_pf(uint32_t cpu, uint64_t line_addr)
{
    /*
     * Init shadow cache
     *
     * Parameters:
     *      - cpu: cpu
     *      - addr: cache block v_addr
     *
     * Return: 1 if the addr is in the l1d cache, 0 otherwise
     */

    for (uint32_t i = 0; i < L1D_SET; i++)
    {
        for (uint32_t ii = 0; ii < L1D_WAY; ii++)
        {
            if (scache[cpu][i][ii].addr == line_addr) return scache[cpu][i][ii].pf;
        }
    }

    return 0;
}

uint8_t shadow_cache_latency(uint32_t cpu, uint64_t line_addr)
{
    /*
     * Init shadow cache
     *
     * Parameters:
     *      - cpu: cpu
     *      - addr: cache block v_addr
     *
     * Return: 1 if the addr is in the l1d cache, 0 otherwise
     */

    for (uint32_t i = 0; i < L1D_SET; i++)
    {
        for (uint32_t ii = 0; ii < L1D_WAY; ii++)
        {
            if (scache[cpu][i][ii].addr == line_addr) return scache[cpu][i][ii].lat;
        }
    }
    assert(0);
    return 0;
}


/******************************************************************************/
/*                       History Table functions                               */
/******************************************************************************/
// use a ghb to construct a history table
class ghb_index_table:public LRUSetAssociativeCache<int> {
    typedef LRUSetAssociativeCache<int> Super;
    public:
        ghb_index_table(int size) : Super(size,16) {
            cerr<<"ghb_index_table sets: "<< num_sets<<" ways: "<<num_ways<<endl;
        }
        int find(uint64_t tag){
            Entry *entry = Super::find(tag);
            if(!entry){
                return -1;
            }else{
                return entry->data;
            }
        }
        int insert(uint64_t tag, int data){
            Entry entry = Super::insert(tag,data);
            if(!(entry.valid)){
                return -1;
            }else{
                return entry.data;
            }      
        }
        void update(uint64_t tag, int data){
            Entry *entry = Super::find(tag);
            if(!entry){
                return;
            }else{
                entry->data=data;
                return;
            }
        }
        void mru(uint64_t tag){
            this->set_mru(tag);
        }
        void print_table(){
            vector<Entry> valid_entries = Super::get_valid_entries();
            for(int i = 0; i < valid_entries.size(); i++){
                cout << valid_entries[i].tag << " " <<valid_entries[i].data << endl;
            }
        }

    private:
        uint64_t size;
};

struct global_history_entry{
    uint64_t pc;
    uint64_t address;
    uint64_t timestamp;
    int pc_next;
    int page_next;

};

class ghb_history_table {
    typedef LRUFullyAssociativeCache<global_history_entry> Super;
    public:
        ghb_history_table(int size, int max_len, int pc_index_size, int page_index_size, int pattern_len, int max_his_len):size(size),max_len(max_len),
        pc_index_table(pc_index_size), page_index_table(page_index_size),
        index_pc_table(pc_index_size), 
        pattern_len(pattern_len),ghb(max_len),
        max_his_len(max_his_len) {
            //max_len代表同一个PC或者page的能够拥有的最大长度的历史信息
            cerr <<"max_len"<< this->max_his_len << endl;
            for(int i = 0; i < this->max_len; i++){
                this->ghb[i].pc = 0;
                this->ghb[i].pc_next = this->max_len;
                this->ghb[i].page_next = this->max_len;
                this->ghb[i].address = 0;
                this->ghb[i].timestamp = 0;
            }
            this->tail = 0;
            this->head = 0;
        }
        int find_pc_stride(uint64_t block_number, uint64_t pc, uint64_t latency, uint64_t cycle, int64_t stride[] ){
            block_number = block_number & ADDR_MASK;
            int pc_head = this->pc_index_table.find(pc);
            if(pc_head == -1 ){
                return 0;
